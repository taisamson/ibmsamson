{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/wbqvbi6o6ip0vz55ua5gp17g4f1k7ve9.png\" width = 300, align = \"center\"></a>\n",
    "\n",
    "<h1 align=center><font size = 5>SIMPLE REGULAR EXPRESSIONS WITH R</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will study some simple Regular Expression terms and apply them with R functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "- <p><a href=\"#ref9001\">Loading in Data</a></p>\n",
    "- <p><a href=\"#funyarinpa\">Regular Expressions</a></p>\n",
    "- <p><a href=\"#imyourpoutine\">Regular Expression in R</a></p>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref9001\"></a>\n",
    "# Loading in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in a small list of emails to perform some data analysis and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "email_df <- read.csv(\"https://ibm.box.com/shared/static/cbim8daa5vjf5rf4rlz11330lvqbu7rk.csv\")\n",
    "email_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our simple dataset contains a list of names and a list of their corresponding emails. Let's say we want to simply count the frequency of email domains. But several problems arise before we can even attempt this. If we attempt to simply count the email column, we won't end up with what we want since every email is unique. And if we split the string at the '@', we still won't have what we want since even emails with the same domains might have different regional extensions. So how can we easily extract the necessary data in a quick and easy way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"funyarinpa\"></a>\n",
    "# Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions are generic expressions that are used to match patterns in strings and text. A way we can exemplify this is with a simple expression that can match with an email string. But before we write it, let's look at how an email is structured:\n",
    "\n",
    "<h1 align=center><font size = 3>test@testing.com</font></h1>\n",
    "\n",
    "So, an email is composed by a string followed by an '@' symbol followed by another string. In R regular expressions, we can express this as:\n",
    "\n",
    "<h1 align=center><font size = 3>.+@.+</font></h1>\n",
    "\n",
    "Where:\n",
    "* The '.' symbol matches with any character.\n",
    "* The '+' symbol repeats the previous symbol one or more times. So, '.+' will match with any string.\n",
    "* The '@' symbol only matches with the '@' character.\n",
    "\n",
    "Now, for our problem, which is extracting the domain from an email excluding the regional url code, we need an expression that specifically matches with what we want:\n",
    "\n",
    "<h1 align=center><font size = 3>@.+\\\\.</font></h1>\n",
    "\n",
    "Where the '\\\\.' symbol specifically matches with the '.' character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imyourpoutine\"></a>\n",
    "# Regular Expressions in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some R functions that work with R functions.\n",
    "\n",
    "The grep function below takes in a Regular Expression and a list of strings to search through and returns the positions of where they appear in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grep(\"@.+\",  c(\"test@testing.com\" , \"not an email\", \"test2@testing.com\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grep also has an extra parameter called 'value' that changes the output to display the strings instead of the list positions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grep(\"@.+\",  c(\"test@testing.com\", \"not an email\", \"test2@testing.com\"), value=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function, 'gsub', is a substitution function. It takes in a Regular Expression, the string you want to swap in with the matches and a list of strings you want to perform the swap with. The code cell below updates valid emails with a new domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsub(\"@.+\", \"@newdomain.com\", c(\"test@testing.com\", \"not an email\", \"test2@testing.com\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below, 'regexpr' and 'regmatches', work in conjunction to extract the matches found by a regular expression specified in 'regexpr'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches <- regexpr(\"@.*\", c(\"test@testing.com\", \"not an email\", \"test2@testing.com\"))\n",
    "regmatches(c(\"test@testing.com\", \"not an email\", \"test2@testing.com\"), matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is actually perfect for our problem since we simply need to extract the specific information we want. So let's use it with the Regular Expression we defined above and store the extracted strings in a new column in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches <- regexpr(\"@.*\\\\.\", email_df[,'Email'])\n",
    "email_df[,'Domain'] = regmatches(email_df[,'Email'], matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the resulting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "email_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally construct the frequency table for the domains in our dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table(email_df[,'Domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Gabriel Sousa\n",
    "\n",
    "## References\n",
    "* [Regular Expression in R](http://stat545.com/block022_regular-expression.htmlf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
